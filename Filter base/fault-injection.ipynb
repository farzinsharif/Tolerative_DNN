{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndrWQenca1Jq",
        "outputId": "bf9c13b0-2b70-4257-edce-45c70707ef52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 391/391 [00:20<00:00, 18.66it/s, loss=1.383]\n",
            "Epoch 2/5: 100%|██████████| 391/391 [00:20<00:00, 19.07it/s, loss=1.084]\n",
            "Epoch 3/5: 100%|██████████| 391/391 [00:20<00:00, 18.99it/s, loss=0.674]\n",
            "Epoch 4/5: 100%|██████████| 391/391 [00:19<00:00, 19.80it/s, loss=0.786]\n",
            "Epoch 5/5: 100%|██████████| 391/391 [00:21<00:00, 18.19it/s, loss=0.671]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint to /content/conv4_cifar10.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Baseline accuracy: 72.95 %\n",
            "\n",
            "Injecting random-re-draw fault into 10 % of all filters …\n",
            "Post-fault accuracy: 35.28 %\n",
            "\n",
            "Accuracy drop: 37.67 percentage points\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# Conv-4 on CIFAR-10 + filter-fault injection benchmark\n",
        "# ================================================================\n",
        "!pip install --quiet torch torchvision tqdm\n",
        "\n",
        "import math, random, os, pathlib, torch, torch.nn as nn, torch.optim as optim\n",
        "import torchvision, torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ----------------------------- CONFIG ---------------------------\n",
        "NUM_EPOCHS        = 5         # change me as needed (100 ≈ 88-90 % acc)\n",
        "BATCH_SIZE        = 128\n",
        "LR                = 0.1\n",
        "DEVICE            = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "FAULT_PERCENT     = 10          # % of *all* filters to random-re-draw\n",
        "RANDOM_SEED       = 42\n",
        "PRETRAINED_PATH   = ''          # e.g. '/content/conv4_cifar10.pt' (leave '' to train)\n",
        "SAVE_CHECKPOINT_TO= '/content/conv4_cifar10.pt'\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# -------------------------- DATASET -----------------------------\n",
        "transform_train = T.Compose([\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomCrop(32, padding=4),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "transform_test  = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "testset  = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                        download=True, transform=transform_test)\n",
        "train_loader = DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                          shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(testset,  batch_size=BATCH_SIZE,\n",
        "                          shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# --------------------------- MODEL ------------------------------\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "    def forward(self, x): return self.block(x)\n",
        "\n",
        "class Conv4(nn.Module):\n",
        "    def __init__(self, num_classes=10, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            ConvBlock(in_channels),\n",
        "            ConvBlock(64),\n",
        "            ConvBlock(64),\n",
        "            ConvBlock(64),\n",
        "        )\n",
        "        self.classifier = nn.Linear(64 * 2 * 2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "\n",
        "model = Conv4().to(DEVICE)\n",
        "\n",
        "# ---------------------- TRAIN / LOAD ----------------------------\n",
        "def accuracy(net, loader):\n",
        "    net.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            preds = net(images).argmax(1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total   += labels.size(0)\n",
        "    return 100. * correct / total\n",
        "\n",
        "if PRETRAINED_PATH and pathlib.Path(PRETRAINED_PATH).exists():\n",
        "    model.load_state_dict(torch.load(PRETRAINED_PATH, map_location=DEVICE))\n",
        "    print(f'Loaded pretrained weights from {PRETRAINED_PATH}')\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9,\n",
        "                          weight_decay=5e-4)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
        "                    milestones=[NUM_EPOCHS//2, int(NUM_EPOCHS*0.75)], gamma=0.1)\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        model.train()\n",
        "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            optimizer.zero_grad()\n",
        "            loss = criterion(model(images), labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            pbar.set_postfix({'loss': f'{loss.item():.3f}'})\n",
        "        scheduler.step()\n",
        "\n",
        "    torch.save(model.state_dict(), SAVE_CHECKPOINT_TO)\n",
        "    print(f'Saved checkpoint to {SAVE_CHECKPOINT_TO}')\n",
        "\n",
        "base_acc = accuracy(model, test_loader)\n",
        "print(f'\\nBaseline accuracy: {base_acc:5.2f} %')\n",
        "\n",
        "# ------------------ FILTER FAULT INJECTION ----------------------\n",
        "def redraw_filters(net, percent: float, sigma: float = 0.05):\n",
        "    \"\"\"\n",
        "    Randomly re-draw `percent` % of filters (kernels) from N(0, sigma²),\n",
        "    distributing the selections equally across Conv layers.\n",
        "    \"\"\"\n",
        "    conv_weights = [p for p in net.parameters() if p.ndim == 4]  # 4-D tensors\n",
        "    total_filters = sum(p.size(0) for p in conv_weights)\n",
        "    k = math.floor(total_filters * percent / 100 + 1e-6)\n",
        "\n",
        "    # equal share per layer (may round last layer)\n",
        "    per_layer = [math.floor(k / len(conv_weights))] * len(conv_weights)\n",
        "    for i in range(k - sum(per_layer)):\n",
        "        per_layer[i] += 1\n",
        "\n",
        "    torch.manual_seed(RANDOM_SEED)  # reproducible\n",
        "    for p, n_fault in zip(conv_weights, per_layer):\n",
        "        if n_fault == 0: continue\n",
        "        idx = random.sample(range(p.size(0)), n_fault)\n",
        "        noise = torch.randn_like(p[idx]) * sigma\n",
        "        p.data[idx] = noise\n",
        "\n",
        "print(f'\\nInjecting random-re-draw fault into {FAULT_PERCENT} % of all filters …')\n",
        "redraw_filters(model, FAULT_PERCENT)\n",
        "faulty_acc = accuracy(model, test_loader)\n",
        "print(f'Post-fault accuracy: {faulty_acc:5.2f} %')\n",
        "\n",
        "print(f'\\nAccuracy drop: {base_acc - faulty_acc:5.2f} percentage points')\n"
      ]
    }
  ]
}